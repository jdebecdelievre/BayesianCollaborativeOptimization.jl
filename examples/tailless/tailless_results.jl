using BayesianCollaborativeOptimization
using LinearAlgebra
using Statistics
using JLD2
using Plots
HOME = pwd()
include("$(pwd())/examples/tailless/tailless.jl")
T = Tailless()

##
disciplines = discipline_names(T)
M = map(i->get_metrics(T, "xpu$i", zopt),1:7)
metric = first.(M)
obj = getindex.(M, [2])
sqJ = last.(M)
plot(metric, yaxis=:log10)

##
l = minimum(length, metric)
plot(mean([m[1:l] for m=metric]), yaxis=:log10)
# met = [1.813618, 1.326392, 0.467193, 0.332232, 0.251307, 0.203285, 0.179433, 0.143485, 0.113937, 0.097779, 0.085133, 0.071687, 0.061396, 0.055545, 0.054146, 0.052986, 0.049264, 0.047197, 0.040634, 0.038498, 0.035806, 0.030987, 0.028716, 0.024090, 0.022092, 0.020837, 0.020427, 0.019728, 0.017669, 0.016691,]/2
gmet = [ 0.9395783514629933, 0.6644157664688632, 0.24305338004907254, 0.17855792712535565, 0.13656728089934528, 0.11159422426723604, 0.09911113515752532, 0.08001423078816536, 0.06527614788311345, 0.05723934247593221, 0.05138013348777313, 0.04522013720308668, 0.04036728301607296, 0.03746641125711485, 0.03481941384248512, 0.03376239609724129, 0.031230444212835818, 0.029693000039475236, 0.02658597813187403, 0.025020945003832163, 0.02379023622151321, 0.021621746143340434, 0.020600042846018886, 0.018518185621759747, 0.013758299082697554, 0.013193317834839841, 0.012863455300141397, 0.012502872281513039, 0.011418526185243106, 0.010792017807775733, 0.010674422951337281]
plot!(gmet, yaxis=:log10)

##
i = 8
data = load_data("xpu$i",T)
@load "xpu$i/obj.jld2" Z sqJ obj fsb
datacheck(data)

##
plot(metric[[2,5,8]], yaxis=:log10)
##

solver = SQP(T, Î»=1.)
options = SolveOptions(n_ite=25, ini_samples=1, warm_start_sampler=100)
solve(solver, options)
